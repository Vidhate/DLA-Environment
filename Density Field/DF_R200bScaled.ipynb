{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing r200b scaling\n",
    "The following cells build utilities and computations to develop on the idea presented in the latest update of 25th May in the introduction.<br>\n",
    "r200b will be found from M200b and the background density.\n",
    "\n",
    "## linDensityLOS(i,d)\n",
    "The statistics developed above for LOS analysis have a redundancy due to direction. The density field on either side of a halo of interest should not be treated separately if we believe in the isotropy of the Universe. Hence, a still better estimate should be to analyse the density of the distribution around the halo of interest. This will become clear through the description of the following procedure-\n",
    "<ol>\n",
    "    <li>Lines of Sight are shot parallel to the grid through the centers of all the Halos of interest from a given mock catalogue and the overdensity amplitude is computed at every scale around the halo.</li>\n",
    "    <li>A bracket of <i>L MPc</i> is introduced symmetrically around the Halo of interest. The average linear density of total amplitude enclosed in the bracket is found and plotted against scale. In the formula below <i>i</i> iterates over all grid points contained in the enclosing bracket imposed on the Halo environment.\n",
    "        $$\\lambda(L)=\\dfrac{\\sum_{i}A_i}{L}$$\n",
    "\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell: Libraries imported and general data to be used is loaded\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "colors=['g','b','r']\n",
    "sourcePath=\"../SourceData/\"  # Will not become a member of the git commits because CIC file is 1.1GB\n",
    "fileNames=['b1','b1alpha','b1T10']\n",
    "# Loading CIC data of density field. (512^3)\n",
    "GridSize=512  # cubed of course.\n",
    "cicSource=\"cic_snap049_grid512.dat\"\n",
    "data=np.reshape(np.fromfile(sourcePath+cicSource),(GridSize,GridSize,GridSize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell: Cosmology is defined. Simulation details are listed. Other constants to be used throughout are specified.\n",
    "# Aseem's Cosmology\n",
    "sigma_8=0.811\n",
    "ns=0.961\n",
    "h=0.7\n",
    "Ob=0.045\n",
    "Om=0.276\n",
    "\n",
    "z=2.3         # Redshift specification\n",
    "M_sun=1.989e+30  # M_sun in kg\n",
    "Mega_parsec=3.086e+22  # parsec in metres\n",
    "Delta=200.0   # Overdensity definition = Delta X background\n",
    "rho_cr=((3*(100*h)**2)/(8*np.pi*6.673e-11))*((Mega_parsec/h**3)*1e+6/(M_sun/h))\n",
    "# critical density of the Universe today 3H^2/8Pi*G in units M_sun.h^-1/(MPc.h^-1)^3\n",
    "rho_m=Om*rho_cr # Units same as rho_cr. Don't need redshift considerations in comoving units i.e. Msun/h and MPc/h\n",
    "del_crit=1.69\n",
    "Lbox=150.0   # MPc/h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading master catalogue data and putting it in usbale format\n",
    "masterCat=np.loadtxt(sourcePath+\"out_49.trees\")\n",
    "\n",
    "treesID=np.array(masterCat[:,1],dtype=int)  # ID of halos in the master catalogue\n",
    "treesR200b=np.cbrt((masterCat[:,36]*3)/(4*np.pi*rho_m*200))   # The r200b of each halo from the master catalogue.\n",
    "treesMap=np.column_stack((treesID,treesR200b))\n",
    "treesMap=treesMap[treesMap[:,0].argsort()]   # TreesMap is a 2 column array with R200b for given ID of the halo\n",
    "# TreesMap is sorted wrt the ID column so that Binary Search can be done on it too save shitloads of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the given Halo catalogues from original non-pickled files to get ID's and positions\n",
    "b1=np.loadtxt(sourcePath+'b1.txt')\n",
    "b1alpha=np.loadtxt(sourcePath+'b1alpha.txt')\n",
    "b1T10=np.loadtxt(sourcePath+'b1T10.txt')\n",
    "\n",
    "b1ID,b1alphaID,b1T10ID=np.array(b1[:,0],dtype=int),np.array(b1alpha[:,0],dtype=int),np.array(b1T10[:,0],dtype=int)\n",
    "b1Pos,b1alphaPos,b1T10Pos=[],[],[]\n",
    "\n",
    "b1Pos.append(b1[:,1])\n",
    "b1Pos.append(b1[:,2])\n",
    "b1Pos.append(b1[:,3])\n",
    "b1Pos=np.array(b1Pos)\n",
    "b1Pos=b1Pos.T  # Holds the positions of all the b1 halos in order according to b1T10\n",
    "\n",
    "b1alphaPos.append(b1alpha[:,1])\n",
    "b1alphaPos.append(b1alpha[:,2])\n",
    "b1alphaPos.append(b1alpha[:,3])\n",
    "b1alphaPos=np.array(b1alphaPos)\n",
    "b1alphaPos=b1alphaPos.T\n",
    "\n",
    "b1T10Pos.append(b1T10[:,1])\n",
    "b1T10Pos.append(b1T10[:,2])\n",
    "b1T10Pos.append(b1T10[:,3])\n",
    "b1T10Pos=np.array(b1T10Pos)\n",
    "b1T10Pos=b1T10Pos.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns an array of r200b for each ID passed as an argument, in order\n",
    "# Note that treesMap is sorted on IDs and hence, we can run a Binary Search on it\n",
    "\n",
    "def findR200b(ID):\n",
    "    low,high=0,treesMap[:,0].size-1\n",
    "    while(low<=high):\n",
    "        mid=int(low+(high-low)/2)\n",
    "        if(ID==treesMap[mid,0]):\n",
    "            return(treesMap[mid,1])\n",
    "        elif(ID>treesMap[mid,0]):\n",
    "            low=mid+1\n",
    "        else:\n",
    "            high=mid-1\n",
    "    return(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00645603 0.89497071 1.81024704]\n"
     ]
    }
   ],
   "source": [
    "# consistency check cell. Please ignore.\n",
    "t10r,alphar,b1r=[],[],[]\n",
    "for i in b1ID:\n",
    "    b1r.append(findR200b(i))\n",
    "for j in b1alphaID:\n",
    "    alphar.append(findR200b(j))\n",
    "for k in b1T10ID:\n",
    "    t10r.append(findR200b(k))\n",
    "    \n",
    "b1r=np.array(b1r)\n",
    "alphar=np.array(alphar)\n",
    "t10r=np.array(t10r)\n",
    "print(np.array([(np.mean(10*b1r)),np.mean(10*alphar),np.mean(10*t10r)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helping functions for asymmetric STD calculations in averagedLOS()\n",
    "# Asymmetry in statistics. Data is split into values above and below mean. A different standard deviation is found for each set.\n",
    "\n",
    "# This function finds the STD given the mean value\n",
    "def std_dev(a,mean):\n",
    "    if len(a)==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.sqrt(np.sum((a-mean)**2)/a.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def customStats(pos,DF,mode):\n",
    "    allModes=np.array(['bin','interp'])  # list of all available modes. Add to this list if developed further\n",
    "    if not any(mode==allModes):\n",
    "        print(\"Please enter a valid mode. Current available modes are - \"+str(allModes))\n",
    "        print(\"After entering a valid mode, run again.\")\n",
    "        return\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell tests the code above\n",
    "p=np.array([1.,2.,3.,4.,5.,6.,7.])\n",
    "d=np.array([np.array([1.,2.,3.]),np.array([1.,2.,3.,4.,5.]),np.array([1.]),np.array([1.,2.,3.,4.,5.,6.,7.])],)\n",
    "#res,su,sd=customStats(p,d,'percentile')\n",
    "#print(res,su,sd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The LOS Method implemented has lines always passing parallel to x-axis and through the grid points\n",
    "# Direction specifies which direction the LOS are parallel to\n",
    "# r_lim specifies the limit to which LOS calculations should be done about the central position of the halo\n",
    "# Limit is specified as distance in the real position coordinates\n",
    "# Also presenting the linear density around the halo of interest\n",
    "\n",
    "def simpleR200bLOS(halo,r200b,direction='x'):\n",
    "    pos,df=np.array([]),np.array([])\n",
    "    rlim=10*r200b  # the upper limit to which Density Field should be found\n",
    "    \n",
    "    grid2box=Lbox/GridSize   # MPc/CICcell\n",
    "    box2grid=(GridSize-1)/Lbox   # CICcells/MPc\n",
    "    \n",
    "    # Connvert Halo co-odinates from real space to closest CIC Grid positions\n",
    "    X=int(np.floor(halo[0]*box2grid))\n",
    "    Y=int(np.floor(halo[1]*box2grid))\n",
    "    Z=int(np.floor(halo[2]*box2grid))\n",
    "    \n",
    "    # Initial values directly appended\n",
    "    pos=np.append(pos,0.0)\n",
    "    df=np.append(df,data[X,Y,Z])\n",
    "    \n",
    "    # Appending to front and back of the DF array iteratively, starting from center to make sure center is def included\n",
    "    scale_grid=1\n",
    "    scale=scale_grid*grid2box\n",
    "    while scale<=rlim:   # runs till real scale is less than  rlim. NOt we started from -rlim.\n",
    "        pos=np.append(pos,scale/r200b)\n",
    "        pos=np.concatenate(([-scale/r200b],pos))\n",
    "        \n",
    "        pr,pl=[],[]\n",
    "        if direction=='x':\n",
    "            pr=np.array([X+scale_grid,Y,Z])\n",
    "            pl=np.array([X-scale_grid,Y,Z])\n",
    "        elif direction=='y':\n",
    "            pr=np.array([X,Y+scale_grid,Z])\n",
    "            pl=np.array([X,Y-scale_grid,Z])\n",
    "        elif direction=='z':\n",
    "            pr=np.array([X,Y,Z+scale_grid])   \n",
    "            pl=np.array([X,Y,Z-scale_grid])   \n",
    "        else:\n",
    "            print(\"Please choose a valid direction for the LOS. Valid choices are - x | y | z\")\n",
    "            exit()\n",
    "            \n",
    "        pr[pr>=GridSize]=pr[pr>=GridSize]-GridSize\n",
    "        pr[pr<0]=pr[pr<0]+GridSize   # periodicty of the box considered\n",
    "        df=np.append(df,data[pr[0],pr[1],pr[2]])\n",
    "        \n",
    "        pl[pl>=GridSize]=pl[pl>=GridSize]-GridSize\n",
    "        pl[pl<0]=pl[pl<0]+GridSize   # periodicty of the box considered\n",
    "        \n",
    "        df=np.concatenate(([data[pl[0],pl[1],pl[2]]],df))\n",
    "        \n",
    "        scale_grid+=1\n",
    "        scale=scale_grid*grid2box\n",
    "        \n",
    "    return np.array(pos),np.array(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOS method implemented has lines passing through every halo of each catalogue to give a statistically robust estimate\n",
    "# Arguments to be passed are halo IDs and corresponding positions...\n",
    "# ...how many directions to consider for calculating the LOS - all | x | y | z\n",
    "\n",
    "def averagedLOS_R200b(ID,pos,los_direction='all'):\n",
    "    \n",
    "    options=np.array(['all','x','y','z'])\n",
    "    if not any(options == los_direction):\n",
    "        print(\"Please enter a valid value to direction argument. Valid values -- all | x | y | z\")\n",
    "        print(\"Jupyter Notebook kernel will be killed\")\n",
    "        exit()\n",
    "    \n",
    "    mocks=pos\n",
    "    masterPos,masterDF=[],[]\n",
    "    # masterDF will store LOS DF for each halo in mocks\n",
    "    # resultDF will be the mean of masterDF at each scale\n",
    "    \n",
    "    if los_direction == 'all':\n",
    "        for h in range(0,mocks[:,0].size):\n",
    "            for directn in ['x','y','z']:\n",
    "                scales,df=simpleR200bLOS(mocks[h],findR200b(ID[h]),directn)\n",
    "                masterDF.append(df)\n",
    "                masterPos.append(scales)\n",
    "        \n",
    "    else:\n",
    "        for h in range(0,mocks[:,0].size):\n",
    "            scales,df=simpleR200bLOS(mocks[h],findR200b(ID[h]),los_direction)\n",
    "            masterDF.append(df)\n",
    "            masterPos.append(scales)\n",
    "    \n",
    "    # ---------------------------------------------------------------------------------------------------------------\n",
    "    # No 2 halos have the same R200b values, hence, all the DF values at R/R200b scales are found at different...\n",
    "    #... non-matching scales. Due to this statistics can't be run on these points because we don't have DF values at...\n",
    "    #... a single R/R200b.\n",
    "    # 2 solutions to these are to either make bins or do an interpolation\n",
    "    # Issue with bins is that the mean spacing of R/R200b between two neighboring points is too large and we can fit...\n",
    "    #... only about 3-4 bins on one side of the Halo of interest.\n",
    "    # Issue with interpolation is that the number of points to interpolate between is also very small, evidently,...\n",
    "    #... the interpolation is not expected to be very robust\n",
    "    # ---------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    '''\n",
    "    resultDF,std_up,std_below=customStats(masterPos,masterDF,mode='std') # mode='std' | mode='percentile'\n",
    "    #resultDF,prcntile16,prcntile84=customStats(masterPos,masterDF,mode='percentile')\n",
    "    # 'percentile' mode recommended because 'std' mode might return 0 for stan. dev. due to lack of data points\n",
    "    \n",
    "    if len(masterPos)==len(resultDF):\n",
    "        return masterPos,resultDF,std_up,std_below\n",
    "        #return masterPos,resultDF,prcntile16,prcntile84\n",
    "    else:\n",
    "        print(\"Fatal error. Pos and DF sizes don't match.\")\n",
    "        return\n",
    "    '''\n",
    "    \n",
    "    return masterPos,masterDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p,d=averagedLOS_R200b(b1T10ID,b1T10Pos,'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi,ma=p[0][0],p[0][-1]\n",
    "mi_in,ma_in=0,0\n",
    "i=0\n",
    "for a in p:\n",
    "    if a[0]<mi:\n",
    "        mi=a[0]\n",
    "        mi_in=i\n",
    "    if a[-1]>ma:\n",
    "        ma=a[-1]\n",
    "        ma_in=i\n",
    "    i+=1\n",
    "print(mi,ma)\n",
    "print(mi_in,ma_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=[]\n",
    "m1=[]\n",
    "i=0\n",
    "for a in p:\n",
    "    m.append(np.mean(a[1:]-a[:-1]))\n",
    "    m1.append(a.size)\n",
    "print(np.mean(m),np.mean(m1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is specifically made to run the averagedLOSv2() function because of more complex plotting details.\n",
    "\n",
    "fig,ax=plt.subplots(nrows=3, ncols=1, sharex=True, sharey=True, figsize=(13,18),dpi=200)\n",
    "fig.text(0.5, 0.0, 'Distance from Halo Center (R/R200b)', ha='center',fontsize=20)\n",
    "fig.text(0.0, 0.5, 'Density Contrast', va='center', rotation='vertical',fontsize=20)\n",
    "\n",
    "plt.subplot(3,1,1)\n",
    "plt.plot(p_b1_r, df_b1_r, 'k', color='#A30000',label=\"b1\")\n",
    "plt.fill_between(p_b1_r, pt84_b1_r, pt16_b1_r,alpha=0.5, edgecolor='#FF6B6B', facecolor='#FFADAD')\n",
    "plt.ylim([0.1,3e1])\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3,1,2)\n",
    "plt.plot(p_alpha_r, df_alpha_r, 'k', color='#00086B',label=\"Alpha\")\n",
    "plt.fill_between(p_alpha_r, pt84_alpha_r, pt16_alpha_r,alpha=0.5, edgecolor='#3a9cff', facecolor='#9bcdff')\n",
    "plt.ylim([0.1,3e1])\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3,1,3)\n",
    "plt.plot(p_t10_r, df_t10_r, 'k', color='#036800',label=\"T10\")\n",
    "plt.fill_between(p_t10_r, pt84_t10_r, pt16_t10_r,alpha=0.5, edgecolor='#49c145', facecolor='#96ff93')\n",
    "plt.ylim([0.1,3e1])\n",
    "plt.yscale('log')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
